# Location: project_v2/ui/main_window.py
# Usage: ä¸»è¦–çª—ï¼Œæ•´åˆæ‰€æœ‰åŠŸèƒ½æ¨¡çµ„

from PyQt6.QtWidgets import QMainWindow, QWidget, QVBoxLayout, QLabel, QGraphicsOpacityEffect
from PyQt6.QtCore import Qt, QTimer, QPropertyAnimation, QEasingCurve, pyqtSignal, QRect
from PyQt6.QtGui import QPainter, QPixmap, QFont, QFontDatabase
import os
import cv2
import numpy as np

from core import StateMachine, SystemState, CameraManager, FaceDetector, ArduinoController
from core.ssr_controller import SSRController  # æ–°å¢SSRæ§åˆ¶å™¨
from ui.detection_overlay import DetectionOverlay
from ui.caption_widget import CaptionWidget
from services import OllamaService, ImageService, TTSService
from utils import ConfigLoader, FontManager


class MainWindow(QMainWindow):
    """ä¸»ç¨‹å¼è¦–çª—"""
    
    def __init__(self, startup_params):
        super().__init__()
        self.startup_params = startup_params
        
        # è¨­å®šç¸®æ”¾å› å­å’Œè¦–çª—å°ºå¯¸
        self.scale_factor = 0.5 if startup_params.get('mini_mode', False) else 1.0
        
        # ğŸ’ª ä¿®æ­£è¦–çª—å°ºå¯¸ï¼šæ¢å¾©è±å±æ ¼å¼1080x1920ï¼Œé©é…ç›´ç«‹è¢å¹•
        if startup_params.get('fullscreen', False):
            # å…¨è¢å¹•æ¨¡å¼ä½¿ç”¨è¢å¹•å°ºå¯¸
            from PyQt6.QtWidgets import QApplication
            screen = QApplication.primaryScreen()
            if screen:
                screen_geometry = screen.geometry()
                self.window_width = screen_geometry.width()
                self.window_height = screen_geometry.height()
            else:
                # å‚™ç”¨å°ºå¯¸ï¼ˆæ‚¨çš„è¢å¹•å°ºå¯¸ï¼‰
                self.window_width = 1200
                self.window_height = 1920
        else:
            # è¦–çª—æ¨¡å¼ä½¿ç”¨è±å±æ¯”ä¾‹ï¼Œé©åˆæ‚¨çš„1200x1920ç›´ç«‹è¢å¹•
            base_width = 1200   # æ‚¨çš„è¢å¹•å¯¬åº¦
            base_height = 1920  # æ‚¨çš„è¢å¹•é«˜åº¦  
            self.window_width = int(base_width * self.scale_factor)
            self.window_height = int(base_height * self.scale_factor)
        
        print(f"ğŸ–¥ï¸ è¦–çª—å°ºå¯¸è¨­å®š: {self.window_width}x{self.window_height} (ç¸®æ”¾: {self.scale_factor})")
        
        # è¼‰å…¥è¨­å®š
        self.config_loader = ConfigLoader()
        self.config = self.config_loader.load_period_config()
        self.weapon_config = self.config_loader.load_weapon_config()
        
        # åˆå§‹åŒ–å…ƒä»¶
        self.init_components()
        self.setup_ui()
        self.connect_signals()
        
        # å•Ÿå‹•ç³»çµ± - å»¶é²å•Ÿå‹•ç›¸æ©Ÿä»¥é¿å…é»‘å±
        QTimer.singleShot(100, self.start_system)
        
    def init_components(self):
        """åˆå§‹åŒ–ç³»çµ±å…ƒä»¶"""
        # æ ¸å¿ƒå…ƒä»¶
        self.state_machine = StateMachine(self.config)
        self.camera_manager = CameraManager()
        self.face_detector = FaceDetector(self.config)
        
        # Arduino (é¸é…)
        self.arduino_controller = None
        if self.startup_params['arduino_port']:
            self.arduino_controller = ArduinoController()
            self.arduino_controller.connect(self.startup_params['arduino_port'])
            
        # SSRæ§åˆ¶å™¨
        self.ssr_controller = SSRController(self.arduino_controller)
        
        # æœå‹™
        self.ollama_service = OllamaService()
        self.image_service = ImageService()
        
        # TTS æœå‹™ - æ ¹æ“šé…ç½®å•Ÿç”¨
        tts_enabled = self.startup_params.get('tts_enabled', True)
        self.tts_service = TTSService(enabled=tts_enabled)
        
        # è¨­å®šTTSåƒæ•¸
        if self.tts_service.is_available():
            print(f"TTS æœå‹™å·²å•Ÿç”¨")
        
        # ç‹€æ…‹
        self.current_screenshot_path = None
        self.current_weapons = []
        self.weapon_display_index = 0
        
        # ç‹€æ…‹å®Œæˆè¿½è¹¤
        self.caption_completed = False
        self.tts_completed = True
        self.wait_timer_completed = False
        
        # é˜²æ­¢é‡è¤‡é¡¯ç¤ºå­—å¹•
        self.caption_displayed = False
        
        # FPS è¨ˆç®—
        self.fps_timer = QTimer()
        self.fps_timer.timeout.connect(self.update_fps)
        self.fps_timer.start(1000)
        self.frame_count = 0
        self.current_fps = 0
        
    def setup_ui(self):
        """è¨­å®š UI"""
        title = "DefenseSystem" + (" - Mini Mode" if self.startup_params.get('mini_mode', False) else "")
        self.setWindowTitle(title)
        
        # è¨­å®šè¦–çª—å¤§å°
        if self.startup_params['fullscreen']:
            self.showFullScreen()
        else:
            # ğŸ’ª ä¿®å¾©è¦–çª—å¤§å°ï¼šç§»é™¤é‚Šæ¡†å’Œæ¨™é¡Œæ¬„ï¼ŒçœŸæ­£å¡«æ»¿è¢å¹•
            self.setWindowFlags(Qt.WindowType.FramelessWindowHint)
            self.setFixedSize(self.window_width, self.window_height)
            
            # ç¢ºä¿è¦–çª—å¡«æ»¿è¢å¹•ï¼ˆç§»å‹•åˆ°å·¦ä¸Šè§’ï¼‰
            self.move(0, 0)
            
        # è¨­å®šé»‘è‰²èƒŒæ™¯
        self.setStyleSheet("background-color: black;")
        
        # ä¸»å®¹å™¨
        self.central_widget = QWidget()
        self.setCentralWidget(self.central_widget)
        
        # ç›¸æ©Ÿé¡¯ç¤º
        self.camera_label = QLabel(self.central_widget)
        self.camera_label.resize(self.window_width, self.window_height)
        self.camera_label.setScaledContents(False)
        self.camera_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.camera_label.setStyleSheet("background-color: #111;")
        
        # è¼‰å…¥ä¸­æç¤º
        self.loading_label = QLabel("Loading camera...", self.central_widget)
        loading_font_size = int(self.startup_params.get('loading_text_size', 24) * self.scale_factor)
        self.loading_label.setStyleSheet("""
            color: white;
            font-size: %dpx;
            background-color: transparent;
        """ % loading_font_size)
        self.loading_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.loading_label.resize(self.window_width, 100)
        self.loading_label.move(0, self.window_height // 2 - 50)
        
        # åµæ¸¬å‹•ç•«å±¤
        self.detection_overlay = DetectionOverlay(self.central_widget)
        self.detection_overlay.resize(self.window_width, self.window_height)
        
        # é€£æ¥æª¢æ¸¬ç‹€æ…‹ä¿¡è™Ÿ
        self.detection_overlay.detection_updated.connect(self.on_detection_state_changed)
        
        # æˆªåœ–é¡¯ç¤ºå±¤
        self.screenshot_label = QLabel(self.central_widget)
        self.screenshot_label.resize(self.window_width, self.window_height)
        self.screenshot_label.setScaledContents(True)
        self.screenshot_label.hide()
        
        # å­—å¹•é¡¯ç¤º
        caption_text_size = self.startup_params.get('caption_text_size', 28)
        self.caption_widget = CaptionWidget(self.central_widget, self.scale_factor, caption_text_size)
        self.caption_widget.resize(self.window_width, self.window_height)
        self.caption_widget.hide()
        
        # æ­¦å™¨åœ–ç‰‡é¡¯ç¤º
        self.weapon_label = QLabel(self.central_widget)
        self.weapon_label.resize(self.window_width, self.window_height)
        self.weapon_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.weapon_label.setScaledContents(False)
        self.weapon_label.hide()
        
        # é»‘å±é®ç½©
        self.black_overlay = QLabel(self.central_widget)
        self.black_overlay.resize(self.window_width, self.window_height)
        self.black_overlay.setStyleSheet("background-color: black;")
        self.black_overlay.hide()
        
        # Debug é¡¯ç¤º
        if self.startup_params['debug_mode']:
            self.debug_label = QLabel(self.central_widget)
            self.debug_label.move(int(5 * self.scale_factor), int(5 * self.scale_factor))
            self.debug_label.resize(int(450 * self.scale_factor), int(600 * self.scale_factor))
            debug_font_size = int(self.startup_params.get('debug_text_size', 16) * self.scale_factor)
            self.debug_label.setStyleSheet("""
                color: white;
                background-color: rgba(0, 0, 0, 192);
                padding: %dpx;
                font-family: monospace;
                font-size: %dpx;
                font-weight: bold;
            """ % (int(8 * self.scale_factor), debug_font_size))
            self.debug_label.show()
            
    def connect_signals(self):
        """é€£æ¥ä¿¡è™Ÿ"""
        # ç‹€æ…‹æ©Ÿä¿¡è™Ÿ
        self.state_machine.state_changed.connect(self.on_state_changed)
        self.state_machine.screenshot_requested.connect(self.take_screenshot)
        self.state_machine.llm_analysis_requested.connect(self.start_llm_analysis)
        self.state_machine.caption_display_requested.connect(self.display_caption)
        self.state_machine.spotlight_requested.connect(self.on_spotlight_requested)  # æ–°å¢
        self.state_machine.weapon_display_requested.connect(self.display_weapons)
        self.state_machine.reset_requested.connect(self.reset_system)
        
        # ç›¸æ©Ÿä¿¡è™Ÿ
        self.camera_manager.frame_ready.connect(self.process_frame)
        
        # äººè‡‰åµæ¸¬ä¿¡è™Ÿ
        self.face_detector.face_detected.connect(self.on_face_detected)
        
        # Ollama æœå‹™ä¿¡è™Ÿ
        self.ollama_service.analysis_complete.connect(self.on_llm_complete)
        
        # å­—å¹•å®Œæˆä¿¡è™Ÿ
        self.caption_widget.typing_complete.connect(self.on_caption_typing_complete)
        self.caption_widget.tc_typing_complete.connect(self.on_tc_typing_complete)
        self.caption_widget.en_typing_complete.connect(self.on_en_typing_complete)
        
        # TTS ä¿¡è™Ÿé€£æ¥ - ç¢ºä¿å³æ™‚å­—å¹•åŒæ­¥
        if hasattr(self, 'tts_service') and self.tts_service is not None:
            print("é€£æ¥ TTS æœå‹™ä¿¡è™Ÿä»¥æ”¯æ´å³æ™‚å­—å¹•åŒæ­¥...")
            
            # é€£æ¥ TTS ç”Ÿå‘½é€±æœŸä¿¡è™Ÿ
            self.tts_service.tts_started.connect(self.on_tts_started)
            self.tts_service.tts_finished.connect(self.on_tts_finished)
            self.tts_service.tts_error.connect(self.on_tts_error)
            
            # é€£æ¥é€²åº¦ä¿¡è™Ÿ - é€™æ˜¯å³æ™‚æ‰“å­—æ•ˆæœçš„é—œéµ
            self.tts_service.tts_progress.connect(self.on_tts_progress)
            self.tts_service.tts_progress.connect(self.caption_widget.update_tts_progress)
            
            # é€£æ¥æ–‡å­—ç‰‡æ®µä¿¡è™Ÿ - æä¾›æ›´ç²¾ç´°çš„åŒæ­¥
            self.tts_service.tts_word_progress.connect(self.on_tts_word_progress)
            
            print("âœ… TTS å³æ™‚å­—å¹•åŒæ­¥ä¿¡è™Ÿå·²é€£æ¥")
            
        # SSRæ§åˆ¶å™¨ä¿¡è™Ÿ
        self.ssr_controller.spotlight_ready.connect(self.on_spotlight_ready)
        self.ssr_controller.caption_lighting_ready.connect(self.on_caption_lighting_ready)  # æ–°å¢SSR1å®Œæˆä¿¡è™Ÿ
        
    def start_system(self):
        """å•Ÿå‹•ç³»çµ±"""
        # è¨­å®š No LLM æ¨¡å¼
        self.state_machine.set_no_llm_mode(self.startup_params['no_llm_mode'])
        
        # å•Ÿå‹•ç›¸æ©Ÿ
        self.camera_manager.start(self.startup_params['camera_index'])
        
        # ç¬¬ä¸€å€‹ç•«é¢åˆ°é”æ™‚éš±è—è¼‰å…¥æç¤º
        self.first_frame_received = False
        
        # å•Ÿå‹•ç‹€æ…‹æ©Ÿ
        self.state_machine.start()
        
    def process_frame(self, frame):
        """è™•ç†ç›¸æ©Ÿç•«é¢"""
        self.frame_count += 1
        
        # éš±è—è¼‰å…¥æç¤º
        if not self.first_frame_received:
            self.first_frame_received = True
            self.loading_label.hide()
        
        # å¾ 1920x1080 è£åˆ‡å‡ºä¸­é–“çš„ 1080x1920 è±å±å€åŸŸ
        cropped_frame = self.crop_frame_to_portrait(frame)
        
        # æ ¹æ“š mini mode é€²è¡Œç¸®æ”¾
        if self.startup_params.get('mini_mode', False):
            target_width = int(1200 * 0.5)
            target_height = int(1920 * 0.5)
        else:
            target_width = 1200
            target_height = 1920
        
        # ç¸®æ”¾åˆ°ç›®æ¨™å°ºå¯¸
        if cropped_frame.shape[1] != target_width or cropped_frame.shape[0] != target_height:
            cropped_frame = cv2.resize(cropped_frame, (target_width, target_height), 
                                     interpolation=cv2.INTER_LINEAR)
        
        # åœ¨å¹€ä¸Šç¹ªè£½æª¢æ¸¬æ¡†
        final_frame = self.detection_overlay.draw_on_frame(cropped_frame)
        
        # é¡¯ç¤ºç•«é¢
        qimage = CameraManager.frame_to_qimage(final_frame)
        pixmap = QPixmap.fromImage(qimage)
        self.camera_label.setPixmap(pixmap)
        
        # äººè‡‰åµæ¸¬
        try:
            detection_result = self.face_detector.process_frame(frame)
            current_state = self.state_machine.current_state
            
            if detection_result:
                # èª¿æ•´åµæ¸¬çµæœåº§æ¨™
                adjusted_bbox = self.adjust_detection_coordinates(detection_result, frame.shape, target_width, target_height)
                if adjusted_bbox:
                    self.last_detection_bbox = adjusted_bbox
                    
                    # åªåœ¨ DETECTING ç‹€æ…‹æ›´æ–°ç‹€æ…‹æ©Ÿ
                    if current_state == SystemState.DETECTING:
                        self.state_machine.update_face_detection(True)
                    
                    # æ›´æ–°åµæ¸¬æ¡†å‹•ç•«
                    if current_state not in [SystemState.CAPTION, SystemState.SPOTLIGHT, SystemState.IMG_SHOW]:
                        # å°‡æª¢æ¸¬æ¡†å‘ä¸Šåç§»ä¸€é»ï¼ˆç´„æ¡†é«˜åº¦çš„20%ï¼‰
                        frame_offset_y = int(adjusted_bbox['height'] * 0.2)
                        adjusted_y = int(adjusted_bbox['y']) - frame_offset_y
                        
                        # ç¢ºä¿Yåº§æ¨™ä¸æœƒè¶…å‡ºç•«é¢é‚Šç•Œ
                        adjusted_y = max(0, adjusted_y)
                        
                        face_rect = (int(adjusted_bbox['x']), adjusted_y, 
                                   int(adjusted_bbox['width']), int(adjusted_bbox['height']))
                        self.detection_overlay.update_faces([face_rect])
                    else:
                        self.detection_overlay.clear_detections()
                else:
                    self.last_detection_bbox = None
                    if current_state == SystemState.DETECTING:
                        self.state_machine.update_face_detection(False)
                    self.detection_overlay.clear_detections()
            else:
                self.last_detection_bbox = None
                if current_state == SystemState.DETECTING:
                    self.state_machine.update_face_detection(False)
                self.detection_overlay.clear_detections()
        except Exception as e:
            print(f"Face detection processing error: {e}")
            self.last_detection_bbox = None
            if hasattr(self, 'state_machine'):
                current_state = self.state_machine.current_state
                if current_state == SystemState.DETECTING:
                    self.state_machine.update_face_detection(False)
            if hasattr(self, 'detection_overlay'):
                self.detection_overlay.clear_detections()
                
    def crop_frame_to_portrait(self, frame):
        """å¾1920x1080ç›¸æ©Ÿç•«é¢è£åˆ‡å‡ºæ­£ç¢ºæ¯”ä¾‹çš„1200x1920è±å±å€åŸŸ"""
        height, width = frame.shape[:2]
        
        # ç¢ºä¿è¼¸å…¥æ˜¯æ¨™æº–ç›¸æ©Ÿæ ¼å¼
        if width != 1920 or height != 1080:
            frame = cv2.resize(frame, (1920, 1080), interpolation=cv2.INTER_LINEAR)
            height, width = 1080, 1920
        
        # ğŸ’ª ä¿®å¾©è‡‰éƒ¨æ¯”ä¾‹ï¼šé©æ‡‰1200x1920è¢å¹•æ¯”ä¾‹
        # ç›®æ¨™æ¯”ä¾‹ 1200:1920 = 5:8
        # å¾1080é«˜åº¦è¨ˆç®—å°æ‡‰çš„5:8å¯¬åº¦ï¼š1080 * 5/8 = 675åƒç´ 
        target_crop_width = int(1080 * 5 / 8)  # 675åƒç´ 
        
        # å¾1920x1080è£åˆ‡å‡ºä¸­é–“çš„675x1080å€åŸŸ
        crop_x = (1920 - target_crop_width) // 2  # å±…ä¸­è£åˆ‡
        crop_y = 0
        
        # è£åˆ‡å‡ºæ­£ç¢ºæ¯”ä¾‹çš„å€åŸŸ
        cropped_frame = frame[crop_y:crop_y + 1080, crop_x:crop_x + target_crop_width]
        
        # ç¸®æ”¾åˆ°ç›®æ¨™å°ºå¯¸1200x1920ï¼ˆä¿æŒæ­£ç¢ºæ¯”ä¾‹ï¼Œä¸æœƒæ‹‰ä¼¸è®Šå½¢ï¼‰
        portrait_frame = cv2.resize(cropped_frame, (1200, 1920), interpolation=cv2.INTER_LINEAR)
        
        return portrait_frame
        
    def adjust_detection_coordinates(self, detection_result, original_shape, display_width, display_height):
        """èª¿æ•´åµæ¸¬åº§æ¨™ä»¥é…åˆè±å±è£åˆ‡å’Œç¸®æ”¾"""
        # å®‰å…¨æª¢æŸ¥
        if not detection_result or not isinstance(detection_result, dict):
            return None
            
        # æª¢æŸ¥å¿…è¦çš„éµæ˜¯å¦å­˜åœ¨
        required_keys = ['x', 'y', 'width', 'height']
        if not all(key in detection_result for key in required_keys):
            return None
        
        # ğŸ’ª è±å±è£åˆ‡åº§æ¨™èª¿æ•´é‚è¼¯
        # æ­¥é©Ÿ1ï¼šè€ƒæ…®å¾1920x1080è£åˆ‡åˆ°ä¸­é–“1080x1080å€åŸŸçš„å½±éŸ¿
        crop_x_offset = (1920 - 1080) // 2  # 420åƒç´ åç§»
        
        # æª¢æŸ¥åµæ¸¬æ¡†æ˜¯å¦åœ¨è£åˆ‡å€åŸŸå…§
        face_left = detection_result['x']
        face_right = detection_result['x'] + detection_result['width']
        
        # å¦‚æœäººè‡‰å®Œå…¨åœ¨è£åˆ‡å€åŸŸå¤–ï¼Œè¿”å›None
        if face_right < crop_x_offset or face_left > crop_x_offset + 1080:
            return None
        
        # èª¿æ•´Xåº§æ¨™ï¼ˆæ¸›å»è£åˆ‡åç§»ï¼‰
        adjusted_x = max(0, detection_result['x'] - crop_x_offset)
        adjusted_width = min(detection_result['width'], 1080 - adjusted_x)
        
        # Yåº§æ¨™ä¸è®Šï¼ˆæ²’æœ‰Yæ–¹å‘è£åˆ‡ï¼‰
        adjusted_y = detection_result['y']
        adjusted_height = detection_result['height']
        
        # æ­¥é©Ÿ2ï¼šå¾1080x1080ç¸®æ”¾åˆ°1080x1920çš„åº§æ¨™èª¿æ•´
        # Xæ–¹å‘ä¸è®Šï¼ŒYæ–¹å‘æŒ‰1920/1080æ¯”ä¾‹ç¸®æ”¾
        scale_y = 1920 / 1080
        final_y = adjusted_y * scale_y
        final_height = adjusted_height * scale_y
        
        # æ­¥é©Ÿ3ï¼šæœ€çµ‚ç¸®æ”¾åˆ°é¡¯ç¤ºå°ºå¯¸
        final_scale_x = display_width / 1080
        final_scale_y = display_height / 1920
        
        final_result = {
            'x': adjusted_x * final_scale_x,
            'y': final_y * final_scale_y,
            'width': adjusted_width * final_scale_x,
            'height': final_height * final_scale_y,
            'confidence': detection_result.get('confidence', 0)
        }
        
        return final_result
            
    def on_face_detected(self, detected, bbox):
        """è™•ç†äººè‡‰åµæ¸¬çµæœ"""
        pass
    
    def on_detection_state_changed(self, has_faces):
        """è™•ç†æª¢æ¸¬ç‹€æ…‹è®ŠåŒ–"""
        if self.startup_params['debug_mode']:
            print(f"Detection state changed: {'Face detected' if has_faces else 'No face'}")
            
    def on_state_changed(self, state):
        """è™•ç†ç‹€æ…‹è®Šæ›´"""
        print(f"State changed to: {state.value}")
        
        # æ›´æ–° debug é¡¯ç¤º
        if self.startup_params['debug_mode']:
            self.update_debug_info()
            
    def take_screenshot(self):
        """æ“·å–ç•«é¢"""
        self.current_screenshot_path = self.camera_manager.take_screenshot()
        
        if self.current_screenshot_path:
            if self.startup_params['no_llm_mode']:
                default_response = {
                    'caption': 'Emergency defense protocol activated.',
                    'caption_tc': 'ç·Šæ€¥é˜²ç¦¦å”è­°å•Ÿå‹•ã€‚',
                    'weapons': ['01', '02']
                }
                self.state_machine.on_llm_complete(default_response)
            else:
                self.state_machine.llm_analysis_requested.emit(self.current_screenshot_path)
                
    def start_llm_analysis(self, image_path):
        """é–‹å§‹ AI åˆ†æ"""
        weapon_list = self.config_loader.get_weapon_list()
        self.ollama_service.analyze_image(image_path, weapon_list)
        
    def on_llm_complete(self, response):
        """AI åˆ†æå®Œæˆ"""
        self.state_machine.on_llm_complete(response)
        
    def display_caption(self, response):
        """é¡¯ç¤ºå­—å¹•å’Œæˆªåœ–"""
        # é˜²æ­¢é‡è¤‡é¡¯ç¤º
        if self.caption_displayed:
            print("Warning: Caption already displayed, skipping")
            return
            
        self.caption_displayed = True
        
        # é‡ç½®å®Œæˆç‹€æ…‹
        self.caption_completed = False
        self.tts_completed = False  # ä¿®æ­£ï¼šåˆå§‹æ‡‰ç‚º False
        self.wait_timer_completed = False
        
        # å•Ÿå‹•SSR1ï¼ˆå­—å¹•ç‡ˆå…‰ï¼‰
        print("=== CAPTION STATE: Starting SSR1 (caption lighting) ===")
        self.ssr_controller.start_caption_lighting()
        self.ssr_controller.print_debug_status()
        
        # é¡¯ç¤ºæˆªåœ–
        if self.current_screenshot_path:
            original_frame = cv2.imread(self.current_screenshot_path)
            if original_frame is not None:
                cropped_frame = self.crop_frame_to_portrait(original_frame)
                
                # ğŸ’ª ä¿®æ­£ç›®æ¨™å°ºå¯¸ï¼šä½¿ç”¨å¯¦éš›è¦–çª—å°ºå¯¸
                target_width = self.window_width
                target_height = self.window_height
                
                if cropped_frame.shape[1] != target_width or cropped_frame.shape[0] != target_height:
                    cropped_frame = cv2.resize(cropped_frame, (target_width, target_height), 
                                             interpolation=cv2.INTER_LINEAR)
                
                qimage = CameraManager.frame_to_qimage(cropped_frame)
                pixmap = QPixmap.fromImage(qimage)
                self.screenshot_label.setPixmap(pixmap)
            
            self.fade_in_widget(self.screenshot_label)
            
        # æª¢æŸ¥å­—å¹•
        caption_tc = response.get('caption_tc', '')
        caption_en = response.get('caption', '')
        typing_speed = self.config.get('caption_typing_speed', 50)
        
        # å„²å­˜æ­¦å™¨åˆ—è¡¨
        self.current_weapons = response.get('weapons', [])
        
        # æº–å‚™TTSå’Œå­—å¹•åŒæ­¥
        if caption_tc and caption_en:
            # é›™èªæ¨¡å¼
            if caption_en and hasattr(self, 'tts_service') and self.tts_service.is_available():
                # ç²å–TTSé ä¼°æ™‚é•·
                tts_duration = self.tts_service.get_estimated_duration(caption_en)
                
                # è¨ˆç®—åŒæ­¥é€Ÿç‡
                tts_rate_wpm = 140
                if hasattr(self.tts_service, 'worker') and self.tts_service.worker and self.tts_service.worker.config:
                    tts_rate_wpm = self.tts_service.worker.config.get_int('rate', 140)
                
                # å•Ÿç”¨åŒæ­¥æ¨¡å¼
                self.caption_widget.enable_tts_sync(caption_en, tts_rate_wpm)
                
                print(f"TTS: Starting synchronized caption display")
                self.tts_completed = False
                self.tts_service.speak_text(caption_en)
            
            self.caption_widget.show_bilingual_caption(caption_tc, caption_en, typing_speed)
        elif caption_tc:
            # åªæœ‰ä¸­æ–‡
            self.caption_widget.show_caption(caption_tc, typing_speed)
        elif caption_en:
            # åªæœ‰è‹±æ–‡
            if hasattr(self, 'tts_service') and self.tts_service.is_available():
                tts_duration = self.tts_service.get_estimated_duration(caption_en)
                tts_rate_wpm = 140
                if hasattr(self.tts_service, 'worker') and self.tts_service.worker and self.tts_service.worker.config:
                    tts_rate_wpm = self.tts_service.worker.config.get_int('rate', 140)
                
                self.caption_widget.enable_tts_sync(caption_en, tts_rate_wpm)
                
                print(f"TTS: Starting synchronized caption display")
                self.tts_completed = False
                self.tts_service.speak_text(caption_en)
            
            self.caption_widget.show_caption(caption_en, typing_speed)
        else:
            # æ²’æœ‰å­—å¹•
            self.caption_completed = True
            self.check_all_completed()
    
    def on_tts_started(self):
        """TTS é–‹å§‹æœ—è®€"""
        if self.startup_params['debug_mode']:
            print("TTS: é–‹å§‹èªéŸ³æœ—è®€")
    
    def on_tts_progress(self, current_pos, total_len):
        """TTSé€²åº¦æ›´æ–° - ç”¨æ–¼å³æ™‚å­—å¹•åŒæ­¥"""
        if self.startup_params['debug_mode']:
            progress = (current_pos / total_len * 100) if total_len > 0 else 0
            print(f"TTS Progress: {current_pos}/{total_len} ({progress:.1f}%) - åŒæ­¥å­—å¹•é¡¯ç¤º")
    
    def on_tts_word_progress(self, current_chunk):
        """TTSå³æ™‚æ–‡å­—ç‰‡æ®µé€²åº¦æ›´æ–° - æä¾›ç²¾ç´°åŒæ­¥"""
        if self.startup_params['debug_mode']:
            print(f"TTS Word Progress: '{current_chunk}' - å³æ™‚å­—å¹•ç‰‡æ®µåŒæ­¥")
    
    def on_tts_error(self, error_msg):
        """TTS éŒ¯èª¤è™•ç†"""
        print(f"TTS Error: {error_msg}")
        
    def on_tc_typing_complete(self):
        """TCå­—å¹•æ‰“å­—å®Œæˆ"""
        print("TC typing complete")
        
    def on_en_typing_complete(self):
        """ENå­—å¹•æ‰“å­—å®Œæˆ"""
        print("EN typing complete")
        
    def on_caption_typing_complete(self):
        """å­—å¹•æ‰“å­—å®Œæˆ"""
        print("All caption typing complete")
        self.caption_completed = True
        
        # å•Ÿå‹•ç­‰å¾…è¨ˆæ™‚å™¨
        wait_time = self.config.get('caption_wait_after', 2.0) * 1000
        QTimer.singleShot(int(wait_time), self.on_wait_timer_complete)
        
    def on_tts_finished(self):
        """TTSæœ—è®€å®Œæˆ"""
        print("TTS speaking complete")
        self.tts_completed = True
        
        # ç¦ç”¨TTSåŒæ­¥æ¨¡å¼
        if hasattr(self, 'caption_widget'):
            self.caption_widget.disable_tts_sync()
            
        self.check_all_completed()
        
    def on_wait_timer_complete(self):
        """ç­‰å¾…è¨ˆæ™‚å™¨å®Œæˆ"""
        print("Wait timer complete")
        self.wait_timer_completed = True
        self.check_all_completed()
        
    def check_all_completed(self):
        """æª¢æŸ¥æ‰€æœ‰äº‹ä»¶æ˜¯å¦å®Œæˆ"""
        if self.caption_completed and self.tts_completed and self.wait_timer_completed:
            print("All caption events completed - transitioning to spotlight")
            self.state_machine.on_caption_complete()
            
    def on_spotlight_requested(self):
        """èšå…‰ç‡ˆç‹€æ…‹è«‹æ±‚"""
        print("=== SPOTLIGHT STATE: Starting SSR2 (spotlight) ===")
        print("Spotlight state requested")
        # å•Ÿå‹•SSR2ï¼ˆèšå…‰ç‡ˆï¼‰
        self.ssr_controller.start_spotlight()
        self.ssr_controller.print_debug_status()
        
    def on_spotlight_ready(self):
        """èšå…‰ç‡ˆæº–å‚™å®Œæˆ"""
        print("Spotlight ready - transitioning to weapon display")
        self.state_machine.on_spotlight_ready()
                         
    def on_caption_lighting_ready(self):
        """å­—å¹•ç‡ˆå…‰æº–å‚™å®Œæˆ"""
        print("Caption lighting (SSR1) ready")
        # SSR1ç‡ˆå…‰æº–å‚™å®Œæˆï¼Œä¸éœ€è¦ç‰¹åˆ¥çš„ç‹€æ…‹è½‰æ›ï¼Œå­—å¹•ç¹¼çºŒé€²è¡Œ
        
    def display_weapons(self, weapon_ids):
        """é¡¯ç¤ºæ­¦å™¨"""
        if not weapon_ids:
            self.state_machine.on_weapon_display_complete()
            return
            
        # éš±è—å­—å¹•å’Œæˆªåœ–
        self.caption_widget.hide()
        self.screenshot_label.hide()
        
        # é¡¯ç¤ºé»‘å±é®ç½©
        self.black_overlay.show()
            
        self.weapon_display_index = 0
        self.current_weapons = weapon_ids
        self.display_next_weapon()
        
    def display_next_weapon(self):
        """é¡¯ç¤ºä¸‹ä¸€å€‹æ­¦å™¨"""
        if self.weapon_display_index >= len(self.current_weapons):
            # æ‰€æœ‰æ­¦å™¨é¡¯ç¤ºå®Œæˆ
            self.black_overlay.hide()
            
            # é—œé–‰æ‰€æœ‰SSRç‡ˆå…‰
            print("=== IMG_SHOW COMPLETE: Stopping all SSR lighting ===")
            self.ssr_controller.stop_all_lighting()
            self.ssr_controller.print_debug_status()
            
            self.state_machine.on_weapon_display_complete()
            return
            
        weapon_id = self.current_weapons[self.weapon_display_index]
        weapon_info = self.weapon_config.get(weapon_id)
        
        print(f"Displaying weapon - ID: {weapon_id}, Index: {self.weapon_display_index}")
        
        if weapon_info:
            # é¡¯ç¤ºæ­¦å™¨åœ–ç‰‡
            self.show_weapon_image(weapon_info)
            
            # æ§åˆ¶ Arduino
            if self.arduino_controller and weapon_info['pin']:
                self.arduino_controller.control_pin(
                    weapon_info['pin'],
                    weapon_info['wait_before'],
                    weapon_info['high_time'],
                    weapon_info['wait_after']
                )
        else:
            print(f"Warning: Weapon ID '{weapon_id}' not found")
                
        self.weapon_display_index += 1
        
        # è¨ˆç®—ä¸‹ä¸€å€‹æ­¦å™¨çš„é¡¯ç¤ºæ™‚é–“
        if weapon_info:
            fade_in = weapon_info.get('image_fade_in', 1.0)
            display = weapon_info.get('image_display', 3.0)
            fade_out = weapon_info.get('image_fade_out', 1.0)
            switch_delay = self.config.get('weapon_switch_delay', 0.5)
            
            total_time = (fade_in + display + fade_out + switch_delay) * 1000
        else:
            total_time = 2000
            
        QTimer.singleShot(int(total_time), self.display_next_weapon)
        
    def show_weapon_image(self, weapon_info):
        """é¡¯ç¤ºæ­¦å™¨åœ–ç‰‡"""
        image_path = os.path.join("weapons_img", weapon_info['image_path'])
        
        if os.path.exists(image_path):
            pixmap = QPixmap(image_path)
            
            if pixmap.isNull():
                print(f"Error: Cannot load image {image_path}")
                return
                
            # ç¸®æ”¾åœ–ç‰‡
            if pixmap.width() > self.window_width or pixmap.height() > self.window_height:
                pixmap = pixmap.scaled(self.window_width, self.window_height, 
                                     Qt.AspectRatioMode.KeepAspectRatio,
                                     Qt.TransformationMode.SmoothTransformation)
                                     
            self.weapon_label.setPixmap(pixmap)
            
            # Fade in
            fade_in_time = weapon_info.get('image_fade_in', 1.0) * 1000
            self.fade_in_weapon_with_black_transition(int(fade_in_time))
            
            # Schedule fade out
            display_time = weapon_info.get('image_display', 3.0) * 1000
            fade_out_time = weapon_info.get('image_fade_out', 1.0) * 1000
            
            QTimer.singleShot(int(display_time), 
                            lambda: self.fade_out_weapon_with_black_transition(int(fade_out_time)))
        else:
            print(f"Error: Weapon image file not found - {image_path}")
        
    def fade_in_weapon_with_black_transition(self, duration):
        """å¸¶é»‘å±è½‰å ´çš„æ­¦å™¨æ·¡å…¥æ•ˆæœ"""
        self.black_overlay.raise_()
        self.black_overlay.show()
        
        self.weapon_label.show()
        
        effect = QGraphicsOpacityEffect()
        self.black_overlay.setGraphicsEffect(effect)
        
        self.fade_animation = QPropertyAnimation(effect, b"opacity")
        self.fade_animation.setDuration(duration)
        self.fade_animation.setStartValue(1)
        self.fade_animation.setEndValue(0)
        self.fade_animation.setEasingCurve(QEasingCurve.Type.InOutQuad)
        self.fade_animation.finished.connect(self.black_overlay.hide)
        self.fade_animation.start()
        
    def fade_out_weapon_with_black_transition(self, duration):
        """å¸¶é»‘å±è½‰å ´çš„æ­¦å™¨æ·¡å‡ºæ•ˆæœ"""
        self.black_overlay.show()
        self.black_overlay.raise_()
        
        effect = QGraphicsOpacityEffect()
        self.black_overlay.setGraphicsEffect(effect)
        
        self.fade_out_animation = QPropertyAnimation(effect, b"opacity")
        self.fade_out_animation.setDuration(duration)
        self.fade_out_animation.setStartValue(0)
        self.fade_out_animation.setEndValue(1)
        self.fade_out_animation.setEasingCurve(QEasingCurve.Type.InOutQuad)
        self.fade_out_animation.finished.connect(self.weapon_label.hide)
        self.fade_out_animation.start()
                            
    def reset_system(self):
        """é‡ç½®ç³»çµ±"""
        # éš±è—æ‰€æœ‰é¡¯ç¤ºå…ƒä»¶
        self.detection_overlay.clear_detections()
        self.screenshot_label.hide()
        self.caption_widget.hide()
        self.weapon_label.hide()
        self.black_overlay.hide()
        
        # åˆªé™¤æˆªåœ–
        if self.current_screenshot_path and os.path.exists(self.current_screenshot_path):
            try:
                os.remove(self.current_screenshot_path)
            except:
                pass
                
        self.current_screenshot_path = None
        self.current_weapons = []
        
        # é‡ç½®ç‹€æ…‹è¿½è¹¤
        self.caption_completed = False
        self.tts_completed = True
        self.wait_timer_completed = False
        self.caption_displayed = False  # é‡ç½®é˜²é‡è¤‡æ¨™è¨˜
        
        # ç¢ºä¿æ‰€æœ‰SSRé—œé–‰
        print("=== RESET: Ensuring all SSR are turned OFF ===")
        self.ssr_controller.stop_all_lighting()
        
    def fade_in_widget(self, widget, duration=None):
        """æ·¡å…¥æ•ˆæœ"""
        if duration is None:
            duration = int(self.config.get('screenshot_fade_in', 1.0) * 1000)
            
        effect = QGraphicsOpacityEffect()
        widget.setGraphicsEffect(effect)
        widget.show()
        
        self.fade_animation = QPropertyAnimation(effect, b"opacity")
        self.fade_animation.setDuration(duration)
        self.fade_animation.setStartValue(0)
        self.fade_animation.setEndValue(1)
        self.fade_animation.setEasingCurve(QEasingCurve.Type.InOutQuad)
        self.fade_animation.start()
        
    def fade_out_widget(self, widget, duration=None):
        """æ·¡å‡ºæ•ˆæœ"""
        if duration is None:
            duration = int(self.config.get('screenshot_fade_out', 1.0) * 1000)
            
        effect = widget.graphicsEffect()
        if not effect:
            effect = QGraphicsOpacityEffect()
            widget.setGraphicsEffect(effect)
            
        self.fade_out_animation = QPropertyAnimation(effect, b"opacity")
        self.fade_out_animation.setDuration(duration)
        self.fade_out_animation.setStartValue(1)
        self.fade_out_animation.setEndValue(0)
        self.fade_out_animation.setEasingCurve(QEasingCurve.Type.InOutQuad)
        self.fade_out_animation.finished.connect(widget.hide)
        self.fade_out_animation.start()
        
    def update_fps(self):
        """æ›´æ–° FPS"""
        self.current_fps = self.frame_count
        self.frame_count = 0
        
        if self.startup_params['debug_mode']:
            self.update_debug_info()
            
    def update_debug_info(self):
        """æ›´æ–° Debug è³‡è¨Š"""
        if hasattr(self, 'debug_label'):
            detection_time = self.state_machine.get_detection_time()
            arduino_status = "Connected" if self.arduino_controller and self.arduino_controller.is_connected else "Not connected"
            llm_mode = "No LLM" if self.startup_params['no_llm_mode'] else "Normal"
            mode = "Mini Mode" if self.startup_params.get('mini_mode', False) else "Full Mode"
            
            weapons_display = "None"
            if hasattr(self, 'current_weapons') and self.current_weapons:
                weapons_display = f"[{', '.join(self.current_weapons)}]"
            
            # SSRç‹€æ…‹
            ssr_status = "Off"
            if hasattr(self, 'ssr_controller'):
                if self.state_machine.current_state in [SystemState.CAPTION, SystemState.SPOTLIGHT, SystemState.IMG_SHOW]:
                    ssr_status = "Active"
            
            # æ­¦å™¨ç‹€æ…‹é¡¯ç¤º
            weapon_status_lines = []
            for weapon_id, weapon_info in self.weapon_config.items():
                weapon_name = weapon_info['name']
                weapon_pin = weapon_info['pin']
                pin_state = "LOW"
                if self.arduino_controller and weapon_pin:
                    pin_state = self.arduino_controller.get_pin_state(weapon_pin)
                weapon_status_lines.append(f"{weapon_id}ï¼š{weapon_name}ï¼ˆD{weapon_pin}ï¼‰:{pin_state}")
            
            # SSRç‹€æ…‹é¡¯ç¤º
            ssr_status_lines = []
            if hasattr(self, 'ssr_controller') and self.ssr_controller.config:
                ssr1_pin = self.ssr_controller.config.ssr1_pin
                ssr2_pin = self.ssr_controller.config.ssr2_pin
                ssr1_state = "LOW"
                ssr2_state = "LOW"
                if self.arduino_controller:
                    ssr1_state = self.arduino_controller.get_pin_state(ssr1_pin)
                    ssr2_state = self.arduino_controller.get_pin_state(ssr2_pin)
                ssr_status_lines.append(f"SSR1ï¼šAllLightInverted (D{ssr1_pin}):{ssr1_state}")
                ssr_status_lines.append(f"SSR2ï¼šSpotLight (D{ssr2_pin}):{ssr2_state}")
            
            debug_text = f"""State: {self.state_machine.current_state.value}
FPS: {self.current_fps}
Detection Time: {detection_time:.1f}s
Arduino: {arduino_status}
SSR: {ssr_status}
LLM Mode: {llm_mode}
Display: {mode}
Weapons: {weapons_display}
Window: {self.window_width}x{self.window_height}
""" + "\n".join(weapon_status_lines) + "\n" + "\n".join(ssr_status_lines)
            
            self.debug_label.setText(debug_text)
            
    def closeEvent(self, event):
        """é—œé–‰äº‹ä»¶"""
        self.state_machine.stop()
        self.camera_manager.stop()
        self.face_detector.release()
        
        if self.arduino_controller:
            self.arduino_controller.disconnect()
        
        # é—œé–‰SSRæ§åˆ¶å™¨
        if hasattr(self, 'ssr_controller'):
            self.ssr_controller.cleanup()
        
        # é—œé–‰TTSæœå‹™
        if hasattr(self, 'tts_service'):
            print("Shutting down TTS service...")
            self.tts_service.shutdown()
            
        event.accept()